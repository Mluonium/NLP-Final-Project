{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.2.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.18.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\miran\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seqeval) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\miran\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate -U\n",
    "%pip install transformers\n",
    "%pip install datasets\n",
    "%pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import load_metric\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next part is annoying but necessary to run the code. You have to have a hugging face account and then go [here](https://huggingface.co/settings/tokens), to get a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3d45b23ab944c49222ee9f1a846fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = True # dw about it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iob2_file(path):\n",
    "    data = []\n",
    "    current_words = []\n",
    "    current_tags = []\n",
    "\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "\n",
    "        if line:\n",
    "            if line[0] == '#':\n",
    "                continue\n",
    "            tok = line.split('\\t')\n",
    "\n",
    "            current_words.append(tok[1])\n",
    "            current_tags.append(tok[2])\n",
    "        else:\n",
    "            if current_words:\n",
    "                data.append((current_words, current_tags))\n",
    "            current_words = []\n",
    "            current_tags = []\n",
    "\n",
    "    if current_tags != []:\n",
    "        data.append((current_words, current_tags))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['words', 'tags'])\n",
    "    df['id'] = df.index\n",
    "    df = df[['id', 'words', 'tags']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                              words  \\\n",
      "0          0             [Where, in, the, world, is, Iguazu, ?]   \n",
      "1          1                                    [Iguazu, Falls]   \n",
      "2          2  [Widely, considered, to, be, one, of, the, mos...   \n",
      "3          3  [The, centre, of, the, falls, is, known, local...   \n",
      "4          4  [With, the, sun, shinning, down, on, the, spra...   \n",
      "...      ...                                                ...   \n",
      "12538  12538  [Even, a, little, time, spent, receiving, whol...   \n",
      "12539  12539  [S., and, I, have, an, acquaintance, who, has,...   \n",
      "12540  12540  [The, urge, to, protect, and, gather, them, al...   \n",
      "12541  12541              [Take, care, ,, my, friend, ,, Linda]   \n",
      "12542  12542  [I, 'm, sorry, to, say, Elena, 's, story, has,...   \n",
      "\n",
      "                                                    tags  \n",
      "0                              [O, O, O, O, O, B-LOC, O]  \n",
      "1                                         [B-LOC, I-LOC]  \n",
      "2      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "4      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "...                                                  ...  \n",
      "12538  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "12539  [B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O,...  \n",
      "12540  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "12541                          [O, O, O, O, O, O, B-PER]  \n",
      "12542  [O, O, O, O, O, B-PER, O, O, O, O, O, O, O, O,...  \n",
      "\n",
      "[12543 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = read_iob2_file(\"en_ewt-ud-train.iob2\")\n",
    "dev_data = read_iob2_file(\"en_ewt-ud-dev.iob2\")\n",
    "test_data = read_iob2_file(\"en_ewt-ud-test-masked.iob2\")\n",
    "print(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag/index dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-LOC': 1, 'I-LOC': 2, 'B-PER': 3, 'B-ORG': 4, 'I-ORG': 5, 'I-PER': 6}\n"
     ]
    }
   ],
   "source": [
    "class Vocab():\n",
    "    def __init__(self, pad_unk='<PAD>'):\n",
    "        self.pad_unk = pad_unk\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "\n",
    "    def getIdx(self, word, add=False):\n",
    "        if word is None or word == self.pad_unk:\n",
    "            return None\n",
    "        if word not in self.word2idx:\n",
    "            if add:\n",
    "                idx = len(self.idx2word)\n",
    "                self.word2idx[word] = idx\n",
    "                self.idx2word.append(word)\n",
    "                return idx\n",
    "            else:\n",
    "                return None\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def getWord(self, idx):\n",
    "        return self.idx2word[idx]\n",
    "\n",
    "label_indices = Vocab()\n",
    "tags_column = train_data[\"tags\"]\n",
    "\n",
    "for tags in tags_column:\n",
    "    for tag in tags:\n",
    "        label_indices.getIdx(tag, add=True)\n",
    "\n",
    "print(label_indices.word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I add new columns to the data that have the translated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Where, in, the, world, is, Iguazu, ?]</td>\n",
       "      <td>[O, O, O, O, O, B-LOC, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Iguazu, Falls]</td>\n",
       "      <td>[B-LOC, I-LOC]</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Widely, considered, to, be, one, of, the, mos...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[The, centre, of, the, falls, is, known, local...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[With, the, sun, shinning, down, on, the, spra...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12538</th>\n",
       "      <td>12538</td>\n",
       "      <td>[Even, a, little, time, spent, receiving, whol...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12539</th>\n",
       "      <td>12539</td>\n",
       "      <td>[S., and, I, have, an, acquaintance, who, has,...</td>\n",
       "      <td>[B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12540</th>\n",
       "      <td>12540</td>\n",
       "      <td>[The, urge, to, protect, and, gather, them, al...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12541</th>\n",
       "      <td>12541</td>\n",
       "      <td>[Take, care, ,, my, friend, ,, Linda]</td>\n",
       "      <td>[O, O, O, O, O, O, B-PER]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12542</th>\n",
       "      <td>12542</td>\n",
       "      <td>[I, 'm, sorry, to, say, Elena, 's, story, has,...</td>\n",
       "      <td>[O, O, O, O, O, B-PER, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12543 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              words  \\\n",
       "0          0             [Where, in, the, world, is, Iguazu, ?]   \n",
       "1          1                                    [Iguazu, Falls]   \n",
       "2          2  [Widely, considered, to, be, one, of, the, mos...   \n",
       "3          3  [The, centre, of, the, falls, is, known, local...   \n",
       "4          4  [With, the, sun, shinning, down, on, the, spra...   \n",
       "...      ...                                                ...   \n",
       "12538  12538  [Even, a, little, time, spent, receiving, whol...   \n",
       "12539  12539  [S., and, I, have, an, acquaintance, who, has,...   \n",
       "12540  12540  [The, urge, to, protect, and, gather, them, al...   \n",
       "12541  12541              [Take, care, ,, my, friend, ,, Linda]   \n",
       "12542  12542  [I, 'm, sorry, to, say, Elena, 's, story, has,...   \n",
       "\n",
       "                                                    tags  \\\n",
       "0                              [O, O, O, O, O, B-LOC, O]   \n",
       "1                                         [B-LOC, I-LOC]   \n",
       "2      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "...                                                  ...   \n",
       "12538  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "12539  [B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "12540  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "12541                          [O, O, O, O, O, O, B-PER]   \n",
       "12542  [O, O, O, O, O, B-PER, O, O, O, O, O, O, O, O,...   \n",
       "\n",
       "                                                 tag_idx  \n",
       "0                                  [0, 0, 0, 0, 0, 1, 0]  \n",
       "1                                                 [1, 2]  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "12538  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "12539  [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "12540  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "12541                              [0, 0, 0, 0, 0, 0, 3]  \n",
       "12542   [0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[12543 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['tag_idx'] = train_data['tags'].apply(lambda x: [label_indices.word2idx[tag] for tag in x])\n",
    "dev_data['tag_idx'] = dev_data['tags'].apply(lambda x: [label_indices.word2idx[tag] for tag in x])\n",
    "test_data['tag_idx'] = test_data['tags'].apply(lambda x: [label_indices.word2idx[tag] for tag in x])\n",
    "\n",
    "model_checkpoint = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(dataset, word_column, tag_column, tokenizer):\n",
    "    tokenized_inputs = tokenizer(dataset[word_column].tolist(), truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(dataset[tag_column]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Where, in, the, world, is, Iguazu, ?]</td>\n",
       "      <td>[O, O, O, O, O, B-LOC, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Iguazu, Falls]</td>\n",
       "      <td>[B-LOC, I-LOC]</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Widely, considered, to, be, one, of, the, mos...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[The, centre, of, the, falls, is, known, local...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[With, the, sun, shinning, down, on, the, spra...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12538</th>\n",
       "      <td>12538</td>\n",
       "      <td>[Even, a, little, time, spent, receiving, whol...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12539</th>\n",
       "      <td>12539</td>\n",
       "      <td>[S., and, I, have, an, acquaintance, who, has,...</td>\n",
       "      <td>[B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12540</th>\n",
       "      <td>12540</td>\n",
       "      <td>[The, urge, to, protect, and, gather, them, al...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12541</th>\n",
       "      <td>12541</td>\n",
       "      <td>[Take, care, ,, my, friend, ,, Linda]</td>\n",
       "      <td>[O, O, O, O, O, O, B-PER]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12542</th>\n",
       "      <td>12542</td>\n",
       "      <td>[I, 'm, sorry, to, say, Elena, 's, story, has,...</td>\n",
       "      <td>[O, O, O, O, O, B-PER, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12543 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              words  \\\n",
       "0          0             [Where, in, the, world, is, Iguazu, ?]   \n",
       "1          1                                    [Iguazu, Falls]   \n",
       "2          2  [Widely, considered, to, be, one, of, the, mos...   \n",
       "3          3  [The, centre, of, the, falls, is, known, local...   \n",
       "4          4  [With, the, sun, shinning, down, on, the, spra...   \n",
       "...      ...                                                ...   \n",
       "12538  12538  [Even, a, little, time, spent, receiving, whol...   \n",
       "12539  12539  [S., and, I, have, an, acquaintance, who, has,...   \n",
       "12540  12540  [The, urge, to, protect, and, gather, them, al...   \n",
       "12541  12541              [Take, care, ,, my, friend, ,, Linda]   \n",
       "12542  12542  [I, 'm, sorry, to, say, Elena, 's, story, has,...   \n",
       "\n",
       "                                                    tags  \\\n",
       "0                              [O, O, O, O, O, B-LOC, O]   \n",
       "1                                         [B-LOC, I-LOC]   \n",
       "2      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "...                                                  ...   \n",
       "12538  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "12539  [B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "12540  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "12541                          [O, O, O, O, O, O, B-PER]   \n",
       "12542  [O, O, O, O, O, B-PER, O, O, O, O, O, O, O, O,...   \n",
       "\n",
       "                                                 tag_idx  \n",
       "0                                  [0, 0, 0, 0, 0, 1, 0]  \n",
       "1                                                 [1, 2]  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "12538  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "12539  [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "12540  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "12541                              [0, 0, 0, 0, 0, 0, 3]  \n",
       "12542   [0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[12543 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[What, is, this, Miramar, ?]</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[It, is, a, place, in, Argentina, lol]</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[what, is, a, good, slogan, for, an, Argentini...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[\", In, Argentina, ,, beef, is, revered, ,, re...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Come, see, how, we, continue, this, tradition...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2072</td>\n",
       "      <td>[The, radical, Shiite, Sadr, movement, issued,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>2073</td>\n",
       "      <td>[The, statement, said, ,, \", We, direct, an, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>2074</td>\n",
       "      <td>[It, called, a, \", ploy, \", the, assertaion, t...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>2075</td>\n",
       "      <td>[The, convergence, of, views, among, the, more...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>2076</td>\n",
       "      <td>[Most, Shiites, ,, however, ,, are, still, rel...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2077 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              words  \\\n",
       "0        0                       [What, is, this, Miramar, ?]   \n",
       "1        1             [It, is, a, place, in, Argentina, lol]   \n",
       "2        2  [what, is, a, good, slogan, for, an, Argentini...   \n",
       "3        3  [\", In, Argentina, ,, beef, is, revered, ,, re...   \n",
       "4        4  [Come, see, how, we, continue, this, tradition...   \n",
       "...    ...                                                ...   \n",
       "2072  2072  [The, radical, Shiite, Sadr, movement, issued,...   \n",
       "2073  2073  [The, statement, said, ,, \", We, direct, an, a...   \n",
       "2074  2074  [It, called, a, \", ploy, \", the, assertaion, t...   \n",
       "2075  2075  [The, convergence, of, views, among, the, more...   \n",
       "2076  2076  [Most, Shiites, ,, however, ,, are, still, rel...   \n",
       "\n",
       "                                                   tags  \\\n",
       "0                                       [O, O, O, O, O]   \n",
       "1                                 [O, O, O, O, O, O, O]   \n",
       "2                        [O, O, O, O, O, O, O, O, O, O]   \n",
       "3               [O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                           [O, O, O, O, O, O, O, O, O]   \n",
       "...                                                 ...   \n",
       "2072  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2073  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2074  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2075  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2076  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                                tag_idx  \n",
       "0                                       [0, 0, 0, 0, 0]  \n",
       "1                                 [0, 0, 0, 0, 0, 0, 0]  \n",
       "2                        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4                           [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                                 ...  \n",
       "2072  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2073  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2074  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2075  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2076  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2077 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = tokenize_and_align_labels(train_data, \"words\", \"tag_idx\", tokenizer)\n",
    "tokenized_dev_data = tokenize_and_align_labels(dev_data, \"words\", \"tag_idx\", tokenizer)\n",
    "tokenized_test_data = tokenize_and_align_labels(test_data, \"words\", \"tag_idx\", tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "label_list = label_indices.idx2word\n",
    "batch_size = 16\n",
    "\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast) # verifies the tokenizers compatibility with hugging face\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))\n",
    "model_name = model_checkpoint.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miran\\AppData\\Local\\Temp\\ipykernel_7868\\3675664793.py:13: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    model_name,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning the data into datasetdicts, to make them compatible with the trainer (otherwise they can't be indexed)\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'id': range(len(tokenized_data['input_ids'])),\n",
    "    'input_ids': tokenized_data['input_ids'],\n",
    "    'attention_mask': tokenized_data['attention_mask'],\n",
    "    'labels': tokenized_data['labels']\n",
    "})\n",
    "\n",
    "dev_dataset = Dataset.from_dict({\n",
    "    'id': range(len(tokenized_dev_data['input_ids'])),\n",
    "    'input_ids': tokenized_dev_data['input_ids'],\n",
    "    'attention_mask': tokenized_dev_data['attention_mask'],\n",
    "    'labels': tokenized_dev_data['labels']\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'id': range(len(tokenized_test_data['input_ids'])),\n",
    "    'input_ids': tokenized_test_data['input_ids'],\n",
    "    'attention_mask': tokenized_test_data['attention_mask'],\n",
    "    'labels': tokenized_test_data['labels']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_sm = train_dataset.select(range(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset_sm,\n",
    "    eval_dataset=dev_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de73da6c36094f409854a45806cdef23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f9e2d6ffcb46bd82f99f3dd7312e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5940914154052734, 'eval_precision': 0.008826583592938734, 'eval_recall': 0.024691358024691357, 'eval_f1': 0.013004398546567222, 'eval_accuracy': 0.7966813274690124, 'eval_runtime': 157.8503, 'eval_samples_per_second': 12.677, 'eval_steps_per_second': 0.798, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd95b57013c428aab4585e3caecd1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3234262466430664, 'eval_precision': 0.0045045045045045045, 'eval_recall': 0.0007262164124909223, 'eval_f1': 0.0012507817385866164, 'eval_accuracy': 0.9223310675729708, 'eval_runtime': 203.3612, 'eval_samples_per_second': 9.84, 'eval_steps_per_second': 0.62, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e9ef04ba73433294179882e1d120ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2209219932556152, 'eval_precision': 0.01282051282051282, 'eval_recall': 0.0007262164124909223, 'eval_f1': 0.0013745704467353953, 'eval_accuracy': 0.9265627082500333, 'eval_runtime': 99.2466, 'eval_samples_per_second': 20.162, 'eval_steps_per_second': 1.27, 'epoch': 3.0}\n",
      "{'train_runtime': 504.8118, 'train_samples_per_second': 0.297, 'train_steps_per_second': 0.024, 'train_loss': 1.4458163579305012, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=1.4458163579305012, metrics={'train_runtime': 504.8118, 'train_samples_per_second': 0.297, 'train_steps_per_second': 0.024, 'train_loss': 1.4458163579305012, 'epoch': 3.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae023405e2c4af2aa573f86442fe202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2209219932556152,\n",
       " 'eval_precision': 0.01282051282051282,\n",
       " 'eval_recall': 0.0007262164124909223,\n",
       " 'eval_f1': 0.0013745704467353953,\n",
       " 'eval_accuracy': 0.9265627082500333,\n",
       " 'eval_runtime': 112.0727,\n",
       " 'eval_samples_per_second': 17.854,\n",
       " 'eval_steps_per_second': 1.124,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28668c14e44049eebfae2ac876e4140b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\miran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0},\n",
       " 'ORG': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0},\n",
       " 'PER': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0},\n",
       " 'overall_precision': 0.0,\n",
       " 'overall_recall': 0.0,\n",
       " 'overall_f1': 0.0,\n",
       " 'overall_accuracy': 0.9970841660387249}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating using dev data\n",
    "dev_dataset_new = Dataset.from_dict({\n",
    "    'input_ids': dev_dataset['input_ids'],\n",
    "    'attention_mask': dev_dataset['attention_mask'],\n",
    "    'labels': dev_dataset['labels']\n",
    "})\n",
    "\n",
    "test_dataset_new = Dataset.from_dict({\n",
    "    'input_ids': test_dataset['input_ids'],\n",
    "    'attention_mask': test_dataset['attention_mask'],\n",
    "    'labels': test_dataset['labels']\n",
    "})\n",
    "\n",
    "predictions, labels, _ = trainer.predict(test_dataset_new)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print predictions and real values side by side\n",
    "for i in range(len(true_predictions)):\n",
    "    print(\"Example\", i+1)\n",
    "    print(\"Predicted:\", true_predictions[i])\n",
    "    print(\"Real:\", true_labels[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the correct format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
