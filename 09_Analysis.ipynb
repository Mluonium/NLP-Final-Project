{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlabeled span-f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readBIO(path):\n",
    "    ents = []\n",
    "    curEnts = []\n",
    "    for line in open(path, encoding = \"utf-8\"):\n",
    "        line = line.strip()\n",
    "        if line == '':\n",
    "            ents.append(curEnts)\n",
    "            curEnts = []\n",
    "        elif line[0] == '#' and len(line.split('\\t')) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            curEnts.append(line.split('\\t')[2][0])\n",
    "    return ents\n",
    "\n",
    "def toSpans(tags):\n",
    "    spans = set()\n",
    "    for beg in range(len(tags)):\n",
    "        if tags[beg][0] == 'B':\n",
    "            end = beg\n",
    "            for end in range(beg+1, len(tags)):\n",
    "                if tags[end][0] != 'I':\n",
    "                    break\n",
    "            spans.add(str(beg) + '-' + str(end))\n",
    "    #print(spans)\n",
    "    return spans\n",
    "\n",
    "def getInstanceScores(predPath, goldPath):\n",
    "    goldEnts = readBIO(goldPath)\n",
    "    predEnts = readBIO(predPath)\n",
    "    entScores = []\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for goldEnt, predEnt in zip(goldEnts, predEnts):\n",
    "        goldSpans = toSpans(goldEnt)\n",
    "        #print(\"goldSpans\", goldSpans)\n",
    "        predSpans = toSpans(predEnt)\n",
    "        #print(\"predSpans\", predSpans)\n",
    "        overlap = len(goldSpans.intersection(predSpans))\n",
    "        #print(\"n_overlap\", overlap)\n",
    "        #print(\"overlap\", goldSpans.intersection(predSpans))\n",
    "        tp += overlap\n",
    "        fp += len(predSpans) - overlap\n",
    "        fn += len(goldSpans) - overlap\n",
    "        \n",
    "    prec = 0.0 if tp+fp == 0 else tp/(tp+fp)\n",
    "    rec = 0.0 if tp+fn == 0 else tp/(tp+fn)\n",
    "    f1 = 0.0 if prec+rec == 0.0 else 2 * (prec * rec) / (prec + rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832468145351581"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = readBIO(\"data/en_ewt-ud-test.iob2\")\n",
    "preds = readBIO(\"data/english_on_en_predictions\")\n",
    "getInstanceScores( \"data/english_on_en_predictions\", \"data/en_ewt-ud-test.iob2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing all the unlabeled span f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_language = \"english\"\n",
    "\n",
    "\n",
    "\n",
    "golden_files = [\"data/zh_pud-ud-test.iob2\",\n",
    "                   \"data/da_ddt-ud-test.iob2\",\n",
    "                   \"data/en_ewt-ud-test.iob2\",\n",
    "                   \"data/de_pud-ud-test.iob2\",\n",
    "                   \"data/pt_pud-ud-test.iob2\",\n",
    "                   \"data/ru_pud-ud-test.iob2\",\n",
    "                   \"data/sk_snk-ud-test.iob2\",\n",
    "                   \"data/sv_pud-ud-test.iob2\",\n",
    "                   \"data/sr_test.iob2\",\n",
    "                   \"data/hr_test.iob2\"\n",
    "\n",
    "                ]\n",
    "\n",
    "predictions = [f\"data/{model_language}_on_zh_predictions\",\n",
    "               f\"data/{model_language}_on_da_predictions\",\n",
    "               f\"data/{model_language}_on_en_predictions\",\n",
    "               f\"data/{model_language}_on_de_predictions\",\n",
    "               f\"data/{model_language}_on_pt_predictions\",\n",
    "               f\"data/{model_language}_on_ru_predictions\",\n",
    "               f\"data/{model_language}_on_sk_predictions\",\n",
    "               f\"data/{model_language}_on_sv_predictions\",\n",
    "               f\"data/{model_language}_on_sr_predictions\",\n",
    "               f\"data/{model_language}_on_hr_predictions\"\n",
    "               ]\n",
    "\n",
    "span = \"unlabel_span_f1.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for data/english_on_zh_predictions:\n",
      "Output: 0.7299726455646737 \n",
      "\n",
      "Result for data/english_on_da_predictions:\n",
      "Output: 0.8313120176405734 \n",
      "\n",
      "Result for data/english_on_en_predictions:\n",
      "Output: 0.832468145351581 \n",
      "\n",
      "Result for data/english_on_de_predictions:\n",
      "Output: 0.8264308980921359 \n",
      "\n",
      "Result for data/english_on_pt_predictions:\n",
      "Output: 0.8531656937584193 \n",
      "\n",
      "Result for data/english_on_ru_predictions:\n",
      "Output: 0.8034894398530761 \n",
      "\n",
      "Result for data/english_on_sk_predictions:\n",
      "Output: 0.7027804410354745 \n",
      "\n",
      "Result for data/english_on_sv_predictions:\n",
      "Output: 0.8782567503552817 \n",
      "\n",
      "Result for data/english_on_sr_predictions:\n",
      "Output: 0.8187772925764193 \n",
      "\n",
      "Result for data/english_on_hr_predictions:\n",
      "Output: 0.8033909357678514 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for golden, preds in zip(golden_files, predictions):\n",
    "    # Run the span script with the corresponding arguments\n",
    "    f1 = getInstanceScores(preds, golden)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Result for {preds}:\")\n",
    "    print(\"Output:\", f1, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
